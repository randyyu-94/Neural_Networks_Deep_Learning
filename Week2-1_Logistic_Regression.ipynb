{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Module 2: Basics of Neural Networks**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I Logistic Regression as a Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Binary Classification\n",
    "\n",
    "- **Concept**: A classifier that can produces a label *y* with 0 (absent) or 1 (present) from a list of feature set *x* with *n* features\n",
    "- ***Notation***: \n",
    "    - (x,y), $x \\in \\textbf{R}^{n_{x}}$, $y \\in \\{0,1\\}$\n",
    "        - **for *m* training example**: ($x^{(1)}$,$y^{(1)}$), ($x^{(2)}$,$y^{(2)}$),... ($x^{(m)}$,$y^{(m)}$)\n",
    "    - $X = [x^{(1)},x^{(2)},...x^{(m)}]$, where $x^{(i)} = [x^{(i)}_{1},x^{(i)}_{2},...x^{(i)}_{n}]^T; X \\in \\textbf{R}^{{n_{x}} \\times m}, X.shape = (n_{x},m)$\n",
    "    - $y = [y^{(1)},y^{(2)},...y^{(m)}], y \\in \\{0,1\\}^{1 \\times m}, y.shape = (1,m)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression\n",
    "\n",
    "- **Concept**: Given *x* ($x \\in \\textbf{R}^{n_{x}}$), produce $\\hat{y}$, where $\\hat{y} = P(y=1|x)$\n",
    "- **Parameter**: $w \\in \\textbf{R}^{n_{x}}, b \\in \\textbf{R}$\n",
    "- **Output**: $\\hat{y} = \\sigma (w^{T}x+b) = \\sigma (z)$\n",
    "    - $z = w^{T}x + b$\n",
    "    - $\\sigma (z) = \\frac{1}{1+e^{-z}}$\n",
    "        - If $z \\rightarrow +\\infty \\Rightarrow e^{-z} \\rightarrow 0 \\Rightarrow \\sigma (z) \\rightarrow 1$\n",
    "        - If $z \\rightarrow -\\infty \\Rightarrow e^{-z} \\rightarrow +\\infty \\Rightarrow \\sigma (z) \\rightarrow 0$\n",
    "    \n",
    "![Sigmoid](resource%20database%20for%20MD%20notes/Week2/1280px-Logistic-curve.svg.png )  \n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$*Sigmoid Function*  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression Cost Function\n",
    "\n",
    "- **Loss(error) function**: $L(\\hat{y},y) = -[y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})]$\n",
    "    - ***Meaning***: a function to measure how good our output $\\hat{y}$ is when the true label is $y$.\n",
    "        - If $y = 1$: $L(\\hat{y},y) = -\\log\\hat{y} \\Rightarrow \\hat{y}_+\\rightarrow 1 \\leftrightarrow L(\\hat{y},y) \\rightarrow 0$\n",
    "        - If $y = 0$: $L(\\hat{y},y) = -\\log(1-\\hat{y}) \\Rightarrow \\hat{y}_-\\rightarrow 0 \\leftrightarrow L(\\hat{y},y) \\rightarrow 0$\n",
    "    - ***Application***: on a single training sample of the whole set\n",
    "- **Cost function**: $J(w,b) = \\frac{1}{m}\\sum\\limits_{i=1}^{m} L(\\hat{y}^{(i)},y^{(i)}) = -\\frac{1}{m} \\sum\\limits_{i=1}^{m} [y^{(i)}\\log\\hat{y}^{(i)}+(1-y^{(i)})\\log(1-\\hat{y}^{(i)})]$\n",
    "    - ***Application***: on the whole sample set\n",
    "    - ***Characteristic***: $\\underline{convex}$, has a minimal value with a set of *w* and *b* (named **global optimum**)\n",
    "- **Task**: Given $\\{(x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}),... (x^{(m)},y^{(m)})\\}$, want $\\hat{y}^{(i)} \\approx y^{(i)}$\n",
    "    - ***Specifically***: Find minimized **cost function** *J* for *w* and *b* factors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Gradient Descent\n",
    "\n",
    "- **Use**: a method to calculate **global optimum** of a model\n",
    "- **Procedures** (only considering *w*):\n",
    "    - 1-1. $w_{new} = w - \\alpha\\frac{\\partial J(w,b)}{\\partial w}$\n",
    "    - 1-2. $b_{new} = b - \\alpha\\frac{\\partial J(w,b)}{\\partial b}$\n",
    "    - 2. *If not* converged [$J(w_{new})< \\mathrm{ all\\ other\\ }J(w)$]:\n",
    "        - 3. *Return to* Step 1\n",
    "    - 4. *Else* converged:\n",
    "        - 5-1. $w_{final} = w_{new}$\n",
    "        - 5-2. $b_{final} = b_{new}$\n",
    "- **Learning rate $\\alpha$**: controls how big a step is taken on each iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Derivatives (Basic)\n",
    "\n",
    "- **Meaning**: the derivative of a function is the slope of the function at a certain point and can vary at different points on the function\n",
    "- **General functions to calculate derivatives**:\n",
    "    - $f(x) = ax^b \\Rightarrow f'(x) = abx^{b-1}$\n",
    "    - $f(x) = \\log_{a}x \\Rightarrow f'(x) = \\frac{1}{x\\ln a} $\n",
    "        - *Special case*: $f(x) = \\ln x \\Rightarrow f'(x) = \\frac{1}{x} $\n",
    "    - $f(x) = a^x \\Rightarrow f'(x) = a^x \\ln a$\n",
    "        - *Special case*: $f(x) = e^x \\Rightarrow f'(x) = e^x$\n",
    "    - $f(x) = \\sin x \\Rightarrow f'(x) = \\cos x$\n",
    "    - $f(x) = \\cos x \\Rightarrow f'(x) = -\\sin x$\n",
    "    - $f(x) = \\tan x \\Rightarrow f'(x) = \\frac{1}{\\cos^2 x}$\n",
    "    - $f(x) = \\cot x \\Rightarrow f'(x) = -\\frac{1}{\\sin^2 x}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Computational Graph\n",
    "\n",
    "- **Use**: Calculate a function (e.g.,  **cost function** *J*) step-by-step from left to right in a graph\n",
    "- **Example**: Given $J = 3(a+bc)=3(a+u)=3v$\n",
    "![Computational graph](resource%20database%20for%20MD%20notes/Week2/Computational_graph.png)\n",
    "    - ***Derivative***: \n",
    "        - $\\frac{\\mathrm{d}J}{\\mathrm{d}v} = 3$ - one-step backward propagation\n",
    "        - $\\frac{\\partial J}{\\partial a} = \\frac{\\mathrm{d}J}{\\mathrm{d}v}\\frac{\\partial v}{\\partial a} = 3\\times 1 = 3$\n",
    "        - $\\frac{\\partial J}{\\partial b} = \\frac{\\mathrm{d}J}{\\mathrm{d}v}\\frac{\\partial v}{\\partial u}\\frac{\\partial u}{\\partial b} =3\\times 1\\times c = 3c$\n",
    "- **Notation in code**: $\\frac{\\mathrm{d}J}{\\mathrm{d}x}$ in code is directly denoted as $\\mathrm{d}x$ to reduce complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
