{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II Python and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Vectorization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### (1) Example of calculating *z* in logistic regression\n",
    "$z = w^Tx + b, \\mathrm{where:} w = \\left[\\begin{array}{c}\n",
    "w_1\\\\\n",
    "w_2\\\\\n",
    "\\vdots\\\\\n",
    "w_{n_x}\n",
    "\\end{array}\\right], x = \\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "\\vdots\\\\\n",
    "x_{n_x}\n",
    "\\end{array}\\right]; w \\in \\textbf{R}^{n_{x}}, x \\in \\textbf{R}^{n_{x}}$\n",
    "\n",
    "- **For non-vectorized (i.e. *for* loop) case**:\n",
    "    - 1. $z = 0$\n",
    "    - 2. for *i* in range($n_x$):\n",
    "        - 3-1. $z\\ +=\\ w^{(i)}x^{(i)}$\n",
    "    - 4. $z\\ +=\\ b$\n",
    "- **for vectorized case**:\n",
    "    - 1. $z = \\mathrm{np.dot}(w,x)+b$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Vectorization saving time (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 249869.8724567009, Vectorized version:0.9975433349609375ms\n"
     ]
    }
   ],
   "source": [
    "# Get the computation time with vectorized method np.dot\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print('c = ' + str(c) + ', Vectorized version:' +str(1000*(toc-tic)) + 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 249869.87245669932, Non-vectorized version:328.11975479125977ms\n"
     ]
    }
   ],
   "source": [
    "# Get the computation time with non-vectorized method for loop \n",
    "tic = time.time()\n",
    "c = 0\n",
    "for ai, bi in zip(a,b):\n",
    "    c += ai*bi\n",
    "toc = time.time()\n",
    "print('c = ' + str(c) + ', Non-vectorized version:' + str(1000*(toc-tic))+'ms')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing the two codes: vectorization speeds up more than **300** times!\n",
    "- Using the internal functions (like *np.dot*) can enable python numpy to use parallelism methods to compute with GPU and CPU much faster.\n",
    "- **Rule of thumb**: whenever possible, avoid explicit *for* loops."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Other vectorization examples\n",
    "$\\boxed{\\textbf{u}_{m} = \\textbf{A}_{mn}\\textbf{v}_{n}}$\n",
    "\n",
    "- **For non-vectorized (i.e. *for* loop) case**:\n",
    "    - 1. $\\textbf{u} = \\mathrm{np.zeros}((n,1))$\n",
    "    - 2. *for* $i\\ \\mathrm{in}\\ \\mathrm{range}(m)$:\n",
    "        - 3. *for* $j\\ \\mathrm{in}\\ \\mathrm{range}(n)$:\n",
    "            - 4. $\\textbf{u}_i\\ += \\textbf{A}_{ij}*\\textbf{v}_j$\n",
    "- **for vectorized case**:\n",
    "    - 1. $\\textbf{u} = \\mathrm{np.dot}(\\textbf{A},\\textbf{v})$  \n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$  \n",
    "\n",
    "$\\boxed{\\textbf{v} =  \\left[\\begin{array}{c}\n",
    "v_1\\\\\n",
    "v_2\\\\\n",
    "\\vdots\\\\\n",
    "v_n\n",
    "\\end{array}\\right] \\Longrightarrow \\textbf{u} = \\left[\\begin{array}{c}\n",
    "e^{v_1}\\\\\n",
    "e^{v_2}\\\\\n",
    "\\vdots\\\\\n",
    "e^{v_n}\n",
    "\\end{array}\\right]}$\n",
    "- **For non-vectorized (i.e. *for* loop) case**:\n",
    "    - 1. $\\textbf{u} = \\mathrm{np.zeros}((n,1))$\n",
    "    - 2. *for* $v_i\\ \\mathrm{in}\\ \\textbf{v}$:\n",
    "        - 3. $u_i = e^{v_i}$\n",
    "- **for vectorized case**:\n",
    "    - 1. $\\textbf{u} = \\mathrm{np.exp}(\\textbf{v})$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$\n",
    "- **Other vectorization codes**:\n",
    "    - np.log(v) - computes natural logarithm of every elements in *v*\n",
    "    - np.abs(v) - computes the absolute value of every elements in *v*\n",
    "    - np.maximum(u,v) - compares every elements in *u* and *v* and provides the maximum of every pair\n",
    "    - v**2 - computes the square of every elements in *v*\n",
    "    - 1/v - computes the inverse of every elements in *v*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Vectorizing Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Original code** (from ***Week2-1**: 7. Logistic Regression Gradient Descent*)\n",
    ">    - 1. Set: $J = 0, \\mathrm{d}w_1 = 0, \\mathrm{d}w_2 = 0, \\mathrm{d}b = 0$\n",
    ">    - 2. *for* $i = 1\\ to\\ m$:\n",
    ">        - 3-1. $z^{(i)} = w^Tx^{(i)}+b$\n",
    ">        - 3-2. $a^{(i)} = \\sigma (z^{(i)})$\n",
    ">        - 3-3. $J\\ +=\\ y^{(i)}\\log a^{(i)} + (1-y^{(i)})\\log(1-a^{(i)}) $\n",
    ">        - 3-4. $\\mathrm{d}z^{(i)} = a^{(i)} - y^{(i)}$\n",
    ">        - 3-5. $\\mathrm{d}w_1\\ +=\\ x_1^{(i)}\\mathrm{d}z^{(i)}$\n",
    ">        - 3-6. $\\mathrm{d}w_2\\ +=\\ x_2^{(i)}\\mathrm{d}z^{(i)}$ - If more than 2 features: another *for* loop\n",
    ">        - 3-7. $\\mathrm{d}b\\ +=\\ \\mathrm{d}z^{(i)}$\n",
    ">    - 4-1. $J := J/m$ - Key step: get *J* value to determine the performance\n",
    ">    - 4-2. $\\mathrm{d}w_1 := \\mathrm{d}w_1/m$\n",
    ">    - 4-3. $\\mathrm{d}w_2 := \\mathrm{d}w_2/m$\n",
    ">    - 4-4. $\\mathrm{d}b := \\mathrm{d}b/m$\n",
    ">    - 5-1. $w_1 := w_1 - \\alpha\\mathrm{d}w_1$\n",
    ">    - 5-2. $w_2 := w_2 - \\alpha\\mathrm{d}w_2$\n",
    ">    - 5-3. $b := b - \\alpha\\mathrm{d}b$\n",
    "\n",
    "- **Vectorizing *for* loop for multiple features**: \n",
    "    - Combine $w_1, w_2, ..., w_n$ into $\\textbf{w}$ and $x_1, x_2, ..., x_n$ into $\\textbf{x}$, and compute $\\mathrm{d}\\textbf{w}\\ += \\textbf{x}^{(i)}\\mathrm{d}z^{(i)}$  \n",
    "    \n",
    "$\\boxed{z^{i}\\ =\\ w^Tx^{(i)}+b, a^{(i)}\\ =\\ \\sigma(z^{(i)})}$, *for* $i\\ \\mathrm{in\\ range}(m)$\n",
    "- **Vectorizing logistic regression prediction *a***\n",
    "    - $\\textbf{z} = [z^{(1)}\\ z^{(2)}\\ ...\\ z^{(m)}],\\textbf{X} = [x^{(1)}\\ x^{(2)}\\ ...\\ x^{(m)}]\\Rightarrow \\textbf{z} = w^T\\textbf{X}+\\textbf{b},\\ where:\\ \\textbf{b}=[b\\ b\\ ...\\ b],1\\times m$\n",
    "    - $[z^{(1)}\\ z^{(2)}\\ ...\\ z^{(m)}] = [w_1\\ w_2\\ ...\\ w_n]\\left[\\begin{array}{c}\n",
    "x_1^{(1)} & x_1^{(2)} & ... & x_1^{(m)}\\\\\n",
    "x_2^{(1)} & x_2^{(2)} & ... & x_2^{(m)}\\\\\n",
    "\\vdots & \\vdots & ... & \\vdots\\\\\n",
    "x_n^{(1)} & x_n^{(2)} & ... & x_n^{(m)}\n",
    "\\end{array}\\right]\\ +[b\\ b\\ ...\\ b] = [\\textbf{w}^T\\textbf{x}^{(1)}+b\\ \\ \\textbf{w}^T\\textbf{x}^{(2)}+b\\ \\ ...\\ \\ \\textbf{w}^T\\textbf{x}^{(m)}+b]$\n",
    "        - **Python code**: Z = np.dot(w.T, X) + b (python expands *b* to 1*m vector and add it to the vector; **broadcasting**)\n",
    "    - $\\textbf{a} = \\sigma(\\textbf{z})$\n",
    "\n",
    "$\\boxed{\\mathrm{d}z^{(i)}\\ =\\ a^{(i)}\\ -\\ y^{(i)}}$\n",
    "- **Vectorizing logistic regression's gradient computation for all *m* training samples**:\n",
    "    - **Vectorizing dz**:\n",
    "        - $\\mathrm{d}\\textbf{z} = [\\mathrm{d}z^{(1)}\\ \\mathrm{d}z^{(2)}\\ ...\\ \\mathrm{d}z^{(m)}],\\textbf{y} = [y^{(1)}\\ y^{(2)}\\ ...\\ y^{(m)}]\\Rightarrow \\mathrm{d}\\textbf{z}\\ =\\ \\textbf{a}\\ -\\ \\textbf{y}$\n",
    "    - **Vectorizing db**:\n",
    "        - **Python code**: db = 1/m\\*np.sum(dz)\n",
    "        - $\\mathrm{d}b\\ = \\frac{1}{m}\\sum\\limits_{i=1}^{m} \\mathrm{d}\\textbf{z}$\n",
    "    - **Vectorizing dw**:\n",
    "        - **Python code**: dw = 1/m\\*X\\*dZ.T\n",
    "        - $\\mathrm{d}\\textbf{w}\\ = \\frac{1}{m}\\textbf{X}\\mathrm{d}z^T \\Leftrightarrow [w_1\\ w_2\\ ...\\ w_n] =\\frac{1}{m}\\left[\\begin{array}{c}\n",
    "x_1^{(1)} & x_1^{(2)} & ... & x_1^{(m)}\\\\\n",
    "x_2^{(1)} & x_2^{(2)} & ... & x_2^{(m)}\\\\\n",
    "\\vdots & \\vdots & ... & \\vdots\\\\\n",
    "x_n^{(1)} & x_n^{(2)} & ... & x_n^{(m)}\n",
    "\\end{array}\\right] \\left[\\begin{array}{c}\n",
    "\\mathrm{d}z^{(1)}\\\\\n",
    "\\mathrm{d}z^{(2)}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathrm{d}z^{(m)}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "\\frac{1}{m}(x_1^{(1)}\\mathrm{d}z^{(1)} + x_1^{(2)}\\mathrm{d}z^{(2)} + ... + x_1^{(m)}\\mathrm{d}z^{(m)})\\\\\n",
    "\\frac{1}{m}(x_2^{(1)}\\mathrm{d}z^{(1)} + x_2^{(2)}\\mathrm{d}z^{(2)} + ... + x_2^{(m)}\\mathrm{d}z^{(m)})\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{1}{m}(x_{n_x}^{(1)}\\mathrm{d}z^{(1)} + x_{n_x}^{(2)}\\mathrm{d}z^{(2)} + ... + x_{n_x}^{(m)}\\mathrm{d}z^{(m)})\n",
    "\\end{array}\\right]$\n",
    "\n",
    "- **Overall flow for one step of gradient descent**:\n",
    "    - Round 0:\n",
    "        - $\\textbf{z} = \\textbf{w}^T\\textbf{X}+b$\n",
    "        - $\\textbf{a} = \\sigma(\\textbf{z})$\n",
    "        - $J = -\\frac{1}{m}\\sum\\limits_{i=1}^{m}[y^{(i)}\\log a^{(i)}+(1-y^{(i)})\\log(1-a^{(i)})]$\n",
    "    - Round 1+:\n",
    "        - $\\mathrm{d}\\textbf{z} = \\textbf{a} - \\textbf{y}$\n",
    "        - $\\mathrm{d}\\textbf{w} = \\frac{1}{m}\\textbf{X}\\mathrm{d}\\textbf{z}^T$\n",
    "        - $\\mathrm{d}b = \\frac{1}{m}\\sum\\limits_{i=1}^{m} \\mathrm{d}\\textbf{z}$\n",
    "        - $\\textbf{w} := \\textbf{w} - \\alpha\\mathrm{d}\\textbf{w}$\n",
    "        - $b := b - \\alpha\\mathrm{d}b$\n",
    "        - $\\textbf{z} = \\textbf{w}^T\\textbf{X}+b$\n",
    "        - $\\textbf{a} = \\sigma(\\textbf{z})$\n",
    "        - $J = -\\frac{1}{m}\\sum\\limits_{i=1}^{m}[y^{(i)}\\log a^{(i)}+(1-y^{(i)})\\log(1-a^{(i)})]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Broadcasting in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Meaning**: when computing a number with a $1\\times x$ matrix, the number will be replicated to a $1\\times x$ matrix and be computed with the matrix. When a matrix with shape of $m\\times n$ computes with a row vector $1\\times n$ or a column vector $m\\times 1$, the row/column of the vector will be replicated to the column/row side until reaching a shape of $m\\times n$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.  239.  155.4  76.9]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[56.0, 0.0, 4.4, 68.0],\n",
    "            [1.2,104.0,52.0,8.0],\n",
    "            [1.8,135.0,99.0,0.9]])\n",
    "\n",
    "cal = A.sum(axis=0) # 0 means vertical computation and 1 means horizontal computation\n",
    "print(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94.91525424  0.          2.83140283 88.42652796]\n",
      " [ 2.03389831 43.51464435 33.46203346 10.40312094]\n",
      " [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n"
     ]
    }
   ],
   "source": [
    "percentage = 100*A/(cal.reshape(1,4))\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=A+B (vertical broadcasting):\n",
      " [[11 22 33 44]\n",
      " [15 26 37 48]\n",
      " [19 30 41 52]]\n",
      "E=A+C (horizontal broadcasting):\n",
      " [[11 12 13 14]\n",
      " [25 26 27 28]\n",
      " [39 40 41 42]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3,4],\n",
    "            [5,6,7,8],\n",
    "            [9,10,11,12]])\n",
    "B = np.array([10,20,30,40])\n",
    "C = np.array([[10],\n",
    "            [20],\n",
    "            [30]])\n",
    "\n",
    "D = A+B\n",
    "E = A+C\n",
    "\n",
    "print('D=A+B (vertical broadcasting):\\n',D)\n",
    "print('E=A+C (horizontal broadcasting):\\n',E)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Array Type in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rank 1 array**\n",
    "    - Contains only one dimension in its shape, shown as *(n,)*\n",
    "    - Is created with one pair of bracket or without an indication of two dimensions\n",
    "    - May cause non-intuitive troubles; **should be generally avoided**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of a1 is:  (5,)\n",
      "the shape of a2 is:  (5,)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([1,2,3,4,5])\n",
    "a2 = np.random.randn(5)\n",
    "\n",
    "print('the shape of a1 is: ', a1.shape)\n",
    "print('the shape of a2 is: ', a2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Row vector**\n",
    "    - Created by setting the number of rows as 1, or by using two brackets in *np.array*\n",
    "    - Can be transposed to a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of r1 is:  (1, 5)\n",
      "the shape of r2 is:  (1, 5)\n",
      "the shape of r1 after transposition is:  (5, 1)\n"
     ]
    }
   ],
   "source": [
    "r1 = np.array([[1,2,3,4,5]])\n",
    "r2 = np.random.randn(1,5)\n",
    "\n",
    "print('the shape of r1 is: ', r1.shape)\n",
    "print('the shape of r2 is: ', r2.shape)\n",
    "\n",
    "c1_r1 = r1.T\n",
    "\n",
    "print('the shape of r1 after transposition is: ', c1_r1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Column vector**\n",
    "    - Created by setting the number of columns as 1, or by using a big bracket enclosing multiple small brackets each with one value in *np.array*\n",
    "    - Can be transposed to a row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of c1 is:  (5, 1)\n",
      "the shape of c2 is:  (5, 1)\n",
      "the shape of c1 after transposition is:  (1, 5)\n"
     ]
    }
   ],
   "source": [
    "c1 = np.array([[1],\n",
    "            [2],\n",
    "            [3],\n",
    "            [4],\n",
    "            [5]])\n",
    "c2 = np.random.randn(5,1)\n",
    "\n",
    "print('the shape of c1 is: ', c1.shape)\n",
    "print('the shape of c2 is: ', c2.shape)\n",
    "\n",
    "r1_c1 = c1.T\n",
    "\n",
    "print('the shape of c1 after transposition is: ', r1_c1.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
