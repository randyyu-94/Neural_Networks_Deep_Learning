{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Module 3: Shallow Neural Network**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I Neural Network Representation and Vectorization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Neural network representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) One hidden layer neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Single Hidden Layer](resource%20database%20for%20MD%20notes/Week3/SingleHiddenLayer.jpg)\n",
    "- **Definition**: A neural network structure that contains a hidden layer prior to its output layer (also called **2-layer network**)\n",
    "- **Terms**:\n",
    "    - Input layer (*layer 0*): $x_1, x_2, x_3 \\Rightarrow X = a^{[0]}$\n",
    "    - Hidden layer (*layer 1*): $a^{[1]}_1,a^{[1]}_2,a^{[1]}_3,a^{[1]}_4 \\Rightarrow a^{[1]}$\n",
    "        - *Hidden* indicates that the true values of these nodes are **not observed**.\n",
    "    - Output layer (*layer 2*): $\\hat{y} = a^{[2]}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Computing a neural network's output on a *single* sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each node of *layer 1* $a_i^{[1]}$:\n",
    "$$\\boxed{z_i^{[1]} = \\textbf{w}_i^{[1]T}\\textbf{x} + b_i^{[1]}, a_i^{[1]} = \\sigma{z_i^{[1]}}}$$\n",
    "where: *superscipt* $^{[1]}$ indicates the No. of *layer*, *subscript* $_i$ indicates the No. of the *node* in this *layer*\n",
    "- For the full *layer 1*:\n",
    "\n",
    "$$\\boxed{\\left\\{\\begin{array}{c}\n",
    "z_1^{[1]} = \\textbf{w}_1^{[1]T}\\textbf{x} + b_1^{[1]}\\\\\n",
    "z_2^{[1]} = \\textbf{w}_2^{[1]T}\\textbf{x} + b_2^{[1]}\\\\\n",
    "z_3^{[1]} = \\textbf{w}_3^{[1]T}\\textbf{x} + b_3^{[1]}\\\\\n",
    "z_4^{[1]} = \\textbf{w}_4^{[1]T}\\textbf{x} + b_4^{[1]}\n",
    "\\end{array}\\right\\}\\Rightarrow \\left\\{\\begin{array}{c}\n",
    "a_1^{[1]} = \\sigma{z_1^{[1]}}\\\\\n",
    "a_2^{[1]} = \\sigma{z_2^{[1]}}\\\\\n",
    "a_3^{[1]} = \\sigma{z_3^{[1]}}\\\\\n",
    "a_4^{[1]} = \\sigma{z_4^{[1]}}\n",
    "\\end{array}\\right\\}}$$\n",
    "- **Vectorization of the calculation**:\n",
    "$$\\boxed{\\left[\\begin{array}{c}\n",
    "z_1^{[1]}\\\\\n",
    "z_2^{[1]}\\\\\n",
    "z_3^{[1]}\\\\\n",
    "z_4^{[1]}\n",
    "\\end{array}\\right] =  \n",
    "\\left[\\begin{array}{c}\n",
    "(w_1^{[1]})_{x_1} & (w_1^{[1]})_{x_2} & (w_1^{[1]})_{x_3}\\\\\n",
    "(w_2^{[1]})_{x_1} & (w_2^{[1]})_{x_2} & (w_2^{[1]})_{x_3}\\\\\n",
    "(w_3^{[1]})_{x_1} & (w_3^{[1]})_{x_2} & (w_3^{[1]})_{x_3}\\\\\n",
    "(w_4^{[1]})_{x_1} & (w_4^{[1]})_{x_2} & (w_4^{[1]})_{x_3}\\\\\n",
    "\\end{array}\\right]\n",
    "\\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_3\n",
    "\\end{array}\\right] + \\left[\\begin{array}{c}\n",
    "b_1^{[1]}\\\\\n",
    "b_2^{[1]}\\\\\n",
    "b_3^{[1]}\\\\\n",
    "b_4^{[1]}\n",
    "\\end{array}\\right]}$$\n",
    "$$\\boxed{\\textbf{z}^{[1]} = \\textbf{w}^{[1]T}\\textbf{x} + \\textbf{b}^{[1]}}$$\n",
    "where: $\\textbf{z}\\mathrm{.shape} = (4,1), \\textbf{w}^{[1]T}\\mathrm{.shape} = (4,3), \\textbf{x}\\mathrm{.shape} = (3,1), \\textbf{b}\\mathrm{.shape} = (4,1)$  \n",
    "$$\\boxed{\\left[\\begin{array}{c}\n",
    "a_1^{[1]}\\\\\n",
    "a_2^{[1]}\\\\\n",
    "a_3^{[1]}\\\\\n",
    "a_4^{[1]}\n",
    "\\end{array}\\right] = \\sigma\\left[\\begin{array}{c}\n",
    "z_1^{[1]}\\\\\n",
    "z_2^{[1]}\\\\\n",
    "z_3^{[1]}\\\\\n",
    "z_4^{[1]}\n",
    "\\end{array}\\right]}$$\n",
    "$$\\boxed{\\textbf{a}^{[1]} = \\sigma(\\textbf{z}^{[1]})}$$\n",
    "where: $\\textbf{a}\\mathrm{.shape} = \\textbf{z}\\mathrm{.shape} = (4,1)$\n",
    "- For the full *layer 2*:\n",
    "$$\\boxed{z^{[2]} = \\textbf{w}^{[2]T}\\textbf{a}^{[1]} + b^{[2]}\\Rightarrow a^{[2]} = \\sigma(z^{[2]})}$$\n",
    "where: $\\textbf{w}^{[2]T}\\mathrm{.shape} = (1,4), \\textbf{a}^{[1]}\\mathrm{.shape} = (4,1)$\n",
    "- **Vectorization of the calculation**:\n",
    "$$\\boxed{z^{[2]} = \\left[\\begin{array}{c}\n",
    "w_1^{[2]} & w_2^{[2]} & w_3^{[2]} & w_4^{[2]}\\end{array}\\right]\n",
    "\\left[\\begin{array}{c}\n",
    "a_1^{[1]}\\\\\n",
    "a_2^{[1]}\\\\\n",
    "a_3^{[1]}\\\\\n",
    "a_4^{[1]}\n",
    "\\end{array}\\right]+b^{[2]}}$$\n",
    "- For the sample:\n",
    "$$\\textbf{z}^{[1]} = \\textbf{w}^{[1]T}\\textbf{x} + \\textbf{b}^{[1]}$$\n",
    "$$\\textbf{a}^{[1]} = \\sigma(\\textbf{z}^{[1]})$$\n",
    "$$z^{[2]} = \\textbf{w}^{[2]T}\\textbf{a}^{[1]} + b^{[2]}$$\n",
    "$$a^{[2]} = \\sigma(z^{[2]})$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Vectorizing across *multiple* examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For *m* samples:\n",
    "    - Denotation of a *node*: $a_l^{[i](j)}$  \n",
    "where: *i* denotes the No. of the *layer*, *j* denotes the No. of the *sample*, and *l* denotes the No. of the *node* in this layer\n",
    "    - *For* loop for all samples:\n",
    "        - *for i = 1 to m*:\n",
    "            - $z^{[1](i)} = w^{[1]T}x^{(i)}+b^{[1]}$\n",
    "            - $a^{[1](i)} = \\sigma(z^{[1](i)})$\n",
    "            - $z^{[2](i)} = w^{[2]T}a^{[1](i)}+b^{[2]}$\n",
    "            - $a^{[2](i)} = \\sigma(z^{[2](i)})$\n",
    "- **Vectorization of the calculation**:\n",
    "$$\\boxed{\\textbf{X} = \\left[\\begin{array}{c}\n",
    "x_1^{(1)} & x_1^{(2)} & ... & x_1^{(m)}\\\\\n",
    "x_2^{(1)} & x_2^{(2)} & ... & x_2^{(m)}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{n_x}^{(1)} & x_{n_x}^{(2)} & ... & x_{n_x}^{(m)}\n",
    "\\end{array}\\right], \\textbf{X}.\\mathrm{shape} = (n_x,m)}$$\n",
    "$$\\boxed{\\textbf{w} = \\left[\\begin{array}{c}\n",
    "w_1^{(1)} & w_1^{(2)} & ... & w_1^{(k_1)}\\\\\n",
    "w_2^{(1)} & w_2^{(2)} & ... & w_2^{(k_1)}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "w_{n_x}^{(1)} & w_{n_x}^{(2)} & ... & w_{n_x}^{(k_1)}\n",
    "\\end{array}\\right], \\textbf{w}.\\mathrm{shape} = (n_x,k_1)}$$\n",
    "By converting $x^{(1)}$ - $x^{(m)}$ to $\\textbf{X}$, we can recompute the equations for all *m* samples:\n",
    "$$\\textbf{Z}^{[1]} = \\textbf{w}^{[1]T}\\textbf{X} + \\textbf{b}^{[1]}$$\n",
    "$$\\textbf{A}^{[1]} = \\sigma(\\textbf{Z}^{[1]})$$\n",
    "where: $\\textbf{A}^{[1]}.\\mathrm{shape} = \\textbf{Z}^{[1]}.\\mathrm{shape} = (k_1,m), \\textbf{w}^{[1]T}.\\mathrm{shape} = (k_1,n_x),\\textbf{X}.\\mathrm{shape} = (n_x,m),\\textbf{b}^{[1]}.\\mathrm{shape} = (k_1,m)( \\mathrm{broadcasted}\\ \\mathrm{from}\\ (k_1,1))$, $k_1$ is the total number of *nodes* in *layer* 1 (i.e., 4 in this example).\n",
    "\n",
    "$$\\textbf{Z}^{[2]} = \\textbf{w}^{[2]T}\\textbf{A}^{[1]} + b^{[2]}$$\n",
    "$$\\textbf{A}^{[2]} = \\sigma(\\textbf{Z}^{[2]})$$\n",
    "where: $\\textbf{A}^{[2]}.\\mathrm{shape} = \\textbf{Z}^{[2]}.\\mathrm{shape} = (1,m), \\textbf{w}^{[2]T}.\\mathrm{shape} = (1,n_x),\\textbf{X}.\\mathrm{shape} = (n_x,m),\\textbf{b}^{[2]}.\\mathrm{shape} = (1,m)( \\mathrm{broadcasted}\\ \\mathrm{from}\\ (1,1))$, assuming *layer* 2 is the *output layer* where $\\textbf{A}^{[2]} = \\hat{\\textbf{Y}}$\n",
    "- **Further explanation for vectorized implementation**:\n",
    "$$\\textbf{w}^{[1]T}\\textbf{X} = \\left[\\begin{array}{c}\n",
    "w_1^{[1](1)} & w_2^{[1](1)} & ... & w_{n_x}^{[1](1)}\\\\\n",
    "w_1^{[1](2)} & w_2^{[1](2)} & ... & w_{n_x}^{[1](2)}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "w_1^{[1](k_1)} & w_2^{[1](k_1)} & ... & w_{n_x}^{[1](k_1)}\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "x_1^{(1)} & x_1^{(2)} & ... & x_1^{(m)}\\\\\n",
    "x_2^{(1)} & x_2^{(2)} & ... & x_2^{(m)}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{n_x}^{(1)} & x_{n_x}^{(2)} & ... & x_{n_x}^{(m)}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "\\sum\\limits_{i=1}^{n_x}w_i^{[1](1)}x_i^{(1)} & \\sum\\limits_{i=1}^{n_x}w_i^{[1](1)}x_i^{(2)} & ... & \\sum\\limits_{i=1}^{n_x}w_i^{[1](1)}x_i^{(m)}\\\\\n",
    "\\sum\\limits_{i=1}^{n_x}w_i^{[1](2)}x_i^{(1)} & \\sum\\limits_{i=1}^{n_x}w_i^{[1](2)}x_i^{(2)} & ... & \\sum\\limits_{i=1}^{n_x}w_i^{[1](2)}x_i^{(m)}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "\\sum\\limits_{i=1}^{n_x}w_i^{[1](k_1)}x_i^{(1)} & \\sum\\limits_{i=1}^{n_x}w_i^{[1](k_1)}x_i^{(2)} & ... & \\sum\\limits_{i=1}^{n_x}w_i^{[1](k_1)}x_i^{(m)}\\\\\n",
    "\\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
